{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Here we have a nueron which looks like a 2D version of the Sputnik satellite. The inputs are our data (famous numbers btw, extra credit if you know what they are (**without** looking them up), Weights are the things we 'tweak', and Bias is another number we can tweak to get the desired output."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "![NEURON](neuron.png) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "inputs = [3.141, 2.1718, 1.618]\n",
    "weights = [.32, .37, .62]\n",
    "bias = 1.38"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The inputs map directly to each weight."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "And doing some simple elementry school multiplication and addition we get an output. We're skipping the Activation function for now."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "4.191846\n"
     ]
    }
   ],
   "source": [
    "output = (inputs[0]*weights[0]+inputs[1]*weights[1]+inputs[2]*weights[2] + bias)\n",
    "print(output)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Good for something simple like this, but scale it up to hundreds of millions/billions, that's way too much typing."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "So, NumPy and Linear Algebra to the rescue!"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Python has lists like our inputs. Linear Algebra also has lists but name them vectors instead. But there is a difference between a row vector and a column vector. A row vector is a 1xN matrix (a 1-dimensional array of numbers) [3.141, 2.1718, 1.618]. A column vector is an Nx1 matrix (a list of numbers arranged vertically).\\\n",
    "3.141 \\\n",
    "2.1718 \\\n",
    "1.618"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "A scalar in Linear Algebra is just a number like our bias, 1.38. The poor little thing has no direction or dimension, also called a 0-dimensional number, or a 0th-order tensor. It just sits there waiting to be called upon. Vectors on the other hand have both magnitude and direction. They got things to do! A vector could be the speed and direction of a baseball pitchers fastball. Our inputs and weights are three-dimensional vectors because they have three numbers. There's no limit to the amount of numbers a vector can contain. Typically denoted as n-dimensional."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In NumPy, a row vector can be represented as a 1-dimensional array, `np.array([3.141, 2.718, 1.618])`, and a column vector as a 2-dimensional array, `np.array([[3.141], [2.718], [1.618]])`. Inputs and weights can be 1-dimensional arrays representing vectors, but these are treated as 1D arrays in NumPy. Vectors in 3D space ([x,y,z]) are represented as 1D arrays in NumPy, though they're conceptually \"3-dimensional.\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Lots of things can be done to vectors: addition, subtraction, scaling, dot product. You've made it out of elementary school I assume, so you're familiar with the first two, scaling changes the magnitude/length of the vector. When referring to vectors those two words are synonymous. But scaling does not change the direction (with one exception). To scale a vector it is **multiplied** by a scalar. Note the difference, a bias shifts the value of the output by a fixed amount but doesn't scale the vector."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Scaling:\n",
    "- Changes the magnitude (length) of a vector.\n",
    "- Does not change the direction of the vector if the scalar is positive.\n",
    "- Flips the direction of the vector if the scalar is negative (reverses direction).\n",
    "- Affects every component of the vector by multiplying them by the scalar.\n",
    "\n",
    "Example: \n",
    "- 2⋅[3,4]=[6,8] (Magnitude doubles, direction remains the same).\n",
    "\n",
    "Example: \n",
    "- −2⋅[3,4]=[−6,−8] (Magnitude doubles, direction flips).\n",
    "\n",
    "Bias:\n",
    "- Shifts the output of a computation, but does not change the magnitude or direction of a vector.\n",
    "- Adds a constant value to the weighted sum of inputs, providing an offset.\n",
    "- Does not affect the vector's components directly; it only changes the output after the weighted sum.\n",
    "- Used in neural networks to allow for flexibility in learning and threshold adjustments."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Dot product** is what was used to calculate the output earlier 4.191846. Take two scalars that have the same number of elements in them, multiply each element, the add to the next two multiplied elements, rinse and repeat. It's easier to visually see what's going on vs. attempting to describe it written out. `(inputs[0]*weights[0] + inputs[1]*weights[1] + inputs[2]*weights[2])`. All of that became one number 4.191846 which is what? That's right, a scalar."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's use NumPy to do the exact same thing."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "4.191846\n"
     ]
    }
   ],
   "source": [
    "np_outputs = np.dot(inputs, weights) +  bias\n",
    "print(np_outputs)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "When it comes to multiplying a vector * vector the commutative property can be used. That is **not** the case when multiplying a vector * matrix or matrix * matrix. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Vector * Matrix"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "a = $$\\left[\\begin{array}{ccc} 1 & 2 & 3 \\end{array}\\right]$$\n",
    "b = $$\\left[\\begin{array}{ccc} 4 & 5 & 6 \\\\  7 & 8 & 9 \\\\ 10 & 11 & 12 \\end{array}\\right]$$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "'a' is 1 row of 3 columns, 1x**3**. 'b' is 3 rows and 3 columns, **3**x3. A vector, only having one row is multiplied with each column in the 'b' matrix. So, the number of elements in the vector, 3 in this case **must** match the number of columns, also 3, in the matrix in order for the math to work."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "np.dot(a,b) = each number in 'a' row 1, which is 3 columns with one row is multipied with each column in matrix 'b'. The output is the opposite of how the dot product is multiplied, so the output will be a 1 x 3 vector in this case."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "np.dot (1x4)+(2x7)+(3x10) \\\n",
    "np.dot (1x5)+(2x8)+(3x11) \\\n",
    "np.dot(1x6)+(2x9)+(3x12) = [48 54 60]\n",
    "$$\\left[\\begin{array}{ccc} 48 & 54 & 60 \\end{array}\\right]$$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "What if we did np.dot(b,a) would the result be the same? First, remember that the first element in a dot product you **must** consider the rows, and the second element the columns. 'a' only has one column in this case, so they cannot be multiplied together currently. BUT, if we were to make 'a' vector, currently 1 row and 3 columns and turn it into 1 column and 3 rows then it would work. $$\\left[\\begin{array}{ccc} 4 & 5 & 6 \\\\  7 & 8 & 9 \\\\ 10 & 11 & 12 \\end{array}\\right]$$ $$\\left[\\begin{array}{c} 1 \\\\ 2 \\\\ 3 \\end{array}\\right]$$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "np.dot(4x1)+(5x2)+(6x3) \\\n",
    "np.dot(7x1)+(8x2)+(9x3) \\\n",
    "np.dot(6x1)+(9x2)+(12x3) = $$\\left[\\begin{array}{c} 32 \\\\ 50 \\\\ 68 \\end{array}\\right]$$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Matrix * Matrix"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Columns of the first matrix must equal the rows of the second matrix. The output will be the number of rows of the first matrix equaling the number of columns of the second matrix. Confusing I know. $$\\begin{bmatrix}\n",
    "a_{11} & a_{12}\\\\ a_{21} & a_{22}\\\\ a_{31} & a_{32}\\\\\n",
    "\\end{bmatrix}$$ $$\\begin{bmatrix}b_{11} & b_{12}\\\\ b_{21} & b_{22}\\\\\\end{bmatrix}$$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "'a' is a 3x2 matrix, and 'b' is a 2x2 matrix. The output will be a 3x2 matrix, 'a' has 3 rows, and 'b' has 2 columns."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "$$\\left[\\begin{matrix}\n",
    "a_{11}&b_{11} + a_{12}&b_{21} & a_{11}&b_{12} + a_{12}&b_{22} \\\\\n",
    "a_{21}&b_{11} + a_{22}&b_{21} & a_{21}&b_{12} + a_{22}&b_{22} \\\\\n",
    "a_{31}&b_{11} + a_{32}&b_{21} & a_{31}&b_{12} + a_{32}&b_{22}\n",
    "\\end{matrix}\\right]$$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
