{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Here we have a nueron which looks like a 2D version of the Sputnik satellite. The inputs are our data (famous numbers btw, extra credit if you know what they are (**without** looking them up), Weights are the things we 'tweak', and Bias is another number we can tweak to get the desired output."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "![NEURON](neuron.png) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "inputs = [3.141, 2.1718, 1.618]\n",
    "weights = [.32, .37, .62]\n",
    "bias = 1.38"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The inputs map directly to each weight."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "And doing some simple elementry school multiplication and addition we get an output. We're skipping the Activation function for now."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "4.191846\n"
     ]
    }
   ],
   "source": [
    "output = (inputs[0]*weights[0]+inputs[1]*weights[1]+inputs[2]*weights[2] + bias)\n",
    "print(output)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Good for something simple like this, but scale it up to hundreds of millions/billions, that's way too much typing."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "So, numpy and Linear Algebra to the rescue!"
   ]
  },
  {
   "attachments": {
    "image.png": {
     "image/png": "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"
    }
   },
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Python has lists like our inputs or bias. Linear Algebra also has lists but name them vectors instead. But there is a difference between a row vector and a column vector. A row vector is a 1xN matrix (a 1-dimensional array of numbers) [3.141, 2.1718, 1.618]. A column vector is an Nx1 matrix (a list of numbers arranged vertically). ![](attachment:image.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "A scalar in Linear Algebra is just a number like our bias, 1.38. The poor little thing has no direction or dimension, 0-dimensional number, or a 0th-order tensor. It just sits there. Vectors on the other hand have both magnitude and direction. They got things to do! A vector could be the speed and direction of a pitchers fastball. Our inputs and weights are three-dimensional vectors because they have three numbers. There's no limit to the amount of numbers a vector can contain. Typically denoted as n-dimensional."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In NumPy, a row vector can be represented as a 1-dimensional array, `np.array([3.141, 2.718, 1.618])`, and a column vector as a 2-dimensional array, `np.array([[3.141], [2.718], [1.618]])`. Inputs and weights can be 1-dimensional arrays representing vectors, but these are treated as 1D arrays in NumPy. Vectors in 3D space ([x,y,z]) are represented as 1D arrays in NumPy, though they're conceptually \"3-dimensional.\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Lots of things can be done to vectors: addition, subtraction, scaling, dot product. You've made it out of elementary school I assume, so you're familiar with the first two, scaling changes the magnitude/length of the vector. When referring to vectors those two words are synonymous. But scaling does not change the direction (with one exception). To scale a vector it is **multiplied** by a scalar. Note the difference, a bias shifts the value of the output by a fixed amount but doesn't scale the vector."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Scaling:\n",
    "- Changes the magnitude (length) of a vector.\n",
    "- Does not change the direction of the vector if the scalar is positive.\n",
    "- Flips the direction of the vector if the scalar is negative (reverses direction).\n",
    "- Affects every component of the vector by multiplying them by the scalar.\n",
    "\n",
    "Example: \n",
    "- 2⋅[3,4]=[6,8] (Magnitude doubles, direction remains the same).\n",
    "\n",
    "Example: \n",
    "- −2⋅[3,4]=[−6,−8] (Magnitude doubles, direction flips).\n",
    "\n",
    "Bias:\n",
    "- Shifts the output of a computation, but does not change the magnitude or direction of a vector.\n",
    "- Adds a constant value to the weighted sum of inputs, providing an offset.\n",
    "- Does not affect the vector's components directly; it only changes the output after the weighted sum.\n",
    "- Used in neural networks to allow for flexibility in learning and threshold adjustments."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Dot product** is what was used to calculate the output earlier 4.191846. Take two scalars that have the same number of elements in them, multiply each element, the add to the next two multiplied elements, rinse and repeat. It's easier to visually see what's going on vs. attempting to describe it written out. `(inputs[0]*weights[0] + inputs[1]*weights[1] + inputs[2]*weights[2])`. All of that became one number 4.191846 which is what? That's right, a scalar."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's use NumPy to do the exact same thing."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "4.191846\n"
     ]
    }
   ],
   "source": [
    "np_outputs = np.dot(inputs, weights) +  bias\n",
    "print(np_outputs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    " "
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
